{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "H100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install captum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2az92YymyKKG",
        "outputId": "41187d4a-1bf6-4313-edb5-a4113a311bfb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: captum in /usr/local/lib/python3.12/dist-packages (0.8.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from captum) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.12/dist-packages (from captum) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from captum) (26.0)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.12/dist-packages (from captum) (2.9.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from captum) (4.67.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.10->captum) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10->captum) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "if not os.path.exists('/content/xai-stability-benchmark'):\n",
        "    os.makedirs('/content/xai-stability-benchmark', exist_ok=True)\n",
        "\n",
        "%cd /content/xai-stability-benchmark\n",
        "!mkdir -p notebooks src data results figures"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDeSvUtFxTJa",
        "outputId": "7aa6e0e3-1412-4ea6-aa73-e5e96e12ad3c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/xai-stability-benchmark\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import models, transforms, datasets\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageEnhance\n",
        "import json\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from scipy.stats import spearmanr\n",
        "from captum.attr import IntegratedGradients, Saliency, LayerGradCam, LayerAttribution\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "model = models.resnet18(pretrained=True).to(device)\n",
        "model.eval()\n",
        "print(\"Model loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_ckdnLixu4V",
        "outputId": "1e0d8be8-0cc1-4b63-e991-aadb6a3e3aab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 418MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = '/content/drive/MyDrive/xai-stability-data'\n",
        "\n",
        "class XAIMethod:\n",
        "    def __init__(self, model, device='cuda'):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.method_name = \"base\"\n",
        "\n",
        "    def preprocess(self, pil_image):\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        return transform(pil_image).unsqueeze(0).to(self.device)\n",
        "\n",
        "    def postprocess_attribution(self, attribution_tensor):\n",
        "        if isinstance(attribution_tensor, torch.Tensor):\n",
        "            attr = attribution_tensor.squeeze().cpu().detach().numpy()\n",
        "        else:\n",
        "            attr = np.array(attribution_tensor).squeeze()\n",
        "\n",
        "        if len(attr.shape) == 3:\n",
        "            attr = np.mean(np.abs(attr), axis=0)\n",
        "        else:\n",
        "            attr = np.abs(attr)\n",
        "\n",
        "        return attr"
      ],
      "metadata": {
        "id": "DmO6_ZTgxz9R"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IntegratedGradientsMethod(XAIMethod):\n",
        "    def __init__(self, model, device='cuda'):\n",
        "        super().__init__(model, device)\n",
        "        self.method_name = \"integrated_gradients\"\n",
        "        self.ig = IntegratedGradients(model)\n",
        "\n",
        "    def generate_attribution(self, input_tensor, target_class):\n",
        "        input_tensor = input_tensor.clone().detach().requires_grad_(True)\n",
        "        attributions = self.ig.attribute(input_tensor, target=target_class, n_steps=50)\n",
        "        return self.postprocess_attribution(attributions)"
      ],
      "metadata": {
        "id": "LKvsqAxf44Sm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GradCAMMethod(XAIMethod):\n",
        "    def __init__(self, model, device='cuda'):\n",
        "        super().__init__(model, device)\n",
        "        self.method_name = \"gradcam\"\n",
        "        self.gradcam = LayerGradCam(model, model.layer4[-1])\n",
        "\n",
        "    def generate_attribution(self, input_tensor, target_class):\n",
        "        attributions = self.gradcam.attribute(input_tensor, target=target_class)\n",
        "        attributions = LayerAttribution.interpolate(attributions, input_tensor.shape[-2:])\n",
        "        return self.postprocess_attribution(attributions)"
      ],
      "metadata": {
        "id": "rPb6k_-m45y3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VanillaGradientsMethod(XAIMethod):\n",
        "    def __init__(self, model, device='cuda'):\n",
        "        super().__init__(model, device)\n",
        "        self.method_name = \"vanilla_gradients\"\n",
        "        self.saliency = Saliency(model)\n",
        "\n",
        "    def generate_attribution(self, input_tensor, target_class):\n",
        "        input_tensor = input_tensor.clone().detach().requires_grad_(True)\n",
        "        attributions = self.saliency.attribute(input_tensor, target=target_class)\n",
        "        return self.postprocess_attribution(attributions)"
      ],
      "metadata": {
        "id": "omrEn5cq48iJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PerturbationGenerator:\n",
        "    def __init__(self, image):\n",
        "        if isinstance(image, torch.Tensor):\n",
        "            image = transforms.ToPILImage()(image)\n",
        "        self.original_image = image\n",
        "\n",
        "    def rotate(self, angle):\n",
        "        return self.original_image.rotate(angle, fillcolor=(128, 128, 128))\n",
        "\n",
        "    def translate(self, x_shift, y_shift):\n",
        "        return self.original_image.transform(\n",
        "            self.original_image.size, Image.AFFINE,\n",
        "            (1, 0, x_shift, 0, 1, y_shift), fillcolor=(128, 128, 128))\n",
        "\n",
        "    def add_gaussian_noise(self, sigma=0.01):\n",
        "        img_array = np.array(self.original_image).astype(np.float32) / 255.0\n",
        "        noise = np.random.normal(0, sigma, img_array.shape)\n",
        "        noisy = np.clip(img_array + noise, 0, 1)\n",
        "        return Image.fromarray((noisy * 255).astype(np.uint8))\n",
        "\n",
        "    def adjust_brightness(self, factor):\n",
        "        enhancer = ImageEnhance.Brightness(self.original_image)\n",
        "        return enhancer.enhance(factor)\n",
        "\n",
        "    def jpeg_compression(self, quality):\n",
        "        from io import BytesIO\n",
        "        buffer = BytesIO()\n",
        "        self.original_image.save(buffer, format='JPEG', quality=quality)\n",
        "        buffer.seek(0)\n",
        "        return Image.open(buffer)\n",
        "\n",
        "    def generate_all_perturbations(self, config=None):\n",
        "        if config is None:\n",
        "            config = {\n",
        "                'rotation': [-5, 5],\n",
        "                'translation': [(-10, -10), (10, 10)],\n",
        "                'noise_sigma': [0.01],\n",
        "                'brightness': [0.9, 1.1],\n",
        "                'jpeg_quality': [85]\n",
        "            }\n",
        "\n",
        "        perturbations = {'original': self.original_image}\n",
        "\n",
        "        for angle in config['rotation']:\n",
        "            perturbations[f'rotate_{angle}'] = self.rotate(angle)\n",
        "        for i, (x, y) in enumerate(config['translation']):\n",
        "            perturbations[f'translate_{i}'] = self.translate(x, y)\n",
        "        for sigma in config['noise_sigma']:\n",
        "            perturbations[f'noise_{sigma}'] = self.add_gaussian_noise(sigma)\n",
        "        for factor in config['brightness']:\n",
        "            perturbations[f'brightness_{factor}'] = self.adjust_brightness(factor)\n",
        "        for quality in config['jpeg_quality']:\n",
        "            perturbations[f'jpeg_{quality}'] = self.jpeg_compression(quality)\n",
        "\n",
        "        return perturbations"
      ],
      "metadata": {
        "id": "ZzOu078H4_E-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimilarityMetrics:\n",
        "    @staticmethod\n",
        "    def normalize_attribution(attr):\n",
        "        attr_min = attr.min()\n",
        "        attr_max = attr.max()\n",
        "        if attr_max - attr_min > 0:\n",
        "            return (attr - attr_min) / (attr_max - attr_min)\n",
        "        return attr\n",
        "\n",
        "    @staticmethod\n",
        "    def ssim_similarity(attr1, attr2):\n",
        "        attr1_norm = SimilarityMetrics.normalize_attribution(attr1)\n",
        "        attr2_norm = SimilarityMetrics.normalize_attribution(attr2)\n",
        "\n",
        "        if attr1_norm.shape != attr2_norm.shape:\n",
        "            raise ValueError(f\"Shape mismatch: {attr1_norm.shape} vs {attr2_norm.shape}\")\n",
        "\n",
        "        score, _ = ssim(attr1_norm, attr2_norm, full=True, data_range=1.0)\n",
        "        return score\n",
        "\n",
        "    @staticmethod\n",
        "    def spearman_similarity(attr1, attr2):\n",
        "        flat1 = attr1.flatten()\n",
        "        flat2 = attr2.flatten()\n",
        "        corr, _ = spearmanr(flat1, flat2)\n",
        "\n",
        "        if np.isnan(corr):\n",
        "            corr = 0.0\n",
        "\n",
        "        return corr\n",
        "\n",
        "    @staticmethod\n",
        "    def top_k_overlap(attr1, attr2, k=100):\n",
        "        flat1 = attr1.flatten()\n",
        "        flat2 = attr2.flatten()\n",
        "\n",
        "        k = min(k, len(flat1))\n",
        "        top_k1 = set(np.argsort(flat1)[-k:])\n",
        "        top_k2 = set(np.argsort(flat2)[-k:])\n",
        "\n",
        "        intersection = len(top_k1 & top_k2)\n",
        "        union = len(top_k1 | top_k2)\n",
        "\n",
        "        return intersection / union if union > 0 else 0.0\n",
        "\n",
        "    @staticmethod\n",
        "    def combined_similarity(attr1, attr2, weights=None):\n",
        "        if weights is None:\n",
        "            weights = {'ssim': 1/3, 'spearman': 1/3, 'topk': 1/3}\n",
        "\n",
        "        ssim_score = SimilarityMetrics.ssim_similarity(attr1, attr2)\n",
        "        spearman_score = SimilarityMetrics.spearman_similarity(attr1, attr2)\n",
        "        topk_score = SimilarityMetrics.top_k_overlap(attr1, attr2, k=100)\n",
        "\n",
        "        ssim_normalized = (ssim_score + 1) / 2\n",
        "        spearman_normalized = (spearman_score + 1) / 2\n",
        "\n",
        "        combined = (\n",
        "            weights['ssim'] * ssim_normalized +\n",
        "            weights['spearman'] * spearman_normalized +\n",
        "            weights['topk'] * topk_score\n",
        "        )\n",
        "\n",
        "        return combined"
      ],
      "metadata": {
        "id": "x3Zm5WM35LM3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FASSCalculator:\n",
        "    def __init__(self, xai_method, similarity_weights=None):\n",
        "        self.xai_method = xai_method\n",
        "        self.similarity_weights = similarity_weights\n",
        "\n",
        "    def compute_fass_for_image(self, original_image, perturbations_dict, target_class):\n",
        "        attributions = {}\n",
        "\n",
        "        for name, img in perturbations_dict.items():\n",
        "            input_tensor = self.xai_method.preprocess(img)\n",
        "            attr = self.xai_method.generate_attribution(input_tensor, target_class)\n",
        "            attributions[name] = attr\n",
        "\n",
        "        names = list(attributions.keys())\n",
        "        similarities = []\n",
        "\n",
        "        for i in range(len(names)):\n",
        "            for j in range(i + 1, len(names)):\n",
        "                sim = SimilarityMetrics.combined_similarity(\n",
        "                    attributions[names[i]],\n",
        "                    attributions[names[j]],\n",
        "                    weights=self.similarity_weights\n",
        "                )\n",
        "                similarities.append({\n",
        "                    'pair': (names[i], names[j]),\n",
        "                    'similarity': sim\n",
        "                })\n",
        "\n",
        "        fass_score = np.mean([s['similarity'] for s in similarities])\n",
        "\n",
        "        return {\n",
        "            'fass_score': fass_score,\n",
        "            'pairwise_similarities': similarities,\n",
        "            'attributions': attributions,\n",
        "            'num_perturbations': len(perturbations_dict)\n",
        "        }"
      ],
      "metadata": {
        "id": "p6bAu99R5Pdh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MY7oJ3FxMKg",
        "outputId": "0a638a0f-db27-427e-8a40-5ed2557a5596"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading CIFAR-10 dataset...\n",
            "Loaded 10000 test images\n",
            "\n",
            "Processing method: integrated_gradients\n",
            "============================================================\n",
            "\n",
            "Batch 1: Images 0-50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:31<00:00,  1.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 2: Images 50-100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:30<00:00,  1.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 3: Images 100-150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:30<00:00,  1.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 4: Images 150-200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:31<00:00,  1.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 5: Images 200-250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:30<00:00,  1.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 6: Images 250-300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:30<00:00,  1.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 7: Images 300-350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:30<00:00,  1.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 8: Images 350-400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:30<00:00,  1.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 9: Images 400-450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:30<00:00,  1.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 10: Images 450-500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:30<00:00,  1.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing method: gradcam\n",
            "============================================================\n",
            "\n",
            "Batch 1: Images 0-50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 2: Images 50-100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 3: Images 100-150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:10<00:00,  4.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 4: Images 150-200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:10<00:00,  4.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 5: Images 200-250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:10<00:00,  4.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 6: Images 250-300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:10<00:00,  4.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 7: Images 300-350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 8: Images 350-400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:10<00:00,  4.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 9: Images 400-450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 10: Images 450-500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing method: vanilla_gradients\n",
            "============================================================\n",
            "\n",
            "Batch 1: Images 0-50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:26<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 2: Images 50-100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:26<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 3: Images 100-150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:26<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 4: Images 150-200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:27<00:00,  1.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 5: Images 200-250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:27<00:00,  1.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 6: Images 250-300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:27<00:00,  1.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 7: Images 300-350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:27<00:00,  1.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 8: Images 350-400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:27<00:00,  1.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 9: Images 400-450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:27<00:00,  1.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 10: Images 450-500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:26<00:00,  1.86it/s]\n"
          ]
        }
      ],
      "source": [
        "print(\"Loading CIFAR-10 dataset...\")\n",
        "transform_simple = transforms.Compose([transforms.ToTensor()])\n",
        "cifar_test = datasets.CIFAR10(root=f'{DATA_DIR}/cifar10', train=False, download=False, transform=transform_simple)\n",
        "print(f\"Loaded {len(cifar_test)} test images\")\n",
        "\n",
        "NUM_IMAGES = 500\n",
        "BATCH_SIZE = 50\n",
        "\n",
        "methods = {\n",
        "    'integrated_gradients': IntegratedGradientsMethod(model, device),\n",
        "    'gradcam': GradCAMMethod(model, device),\n",
        "    'vanilla_gradients': VanillaGradientsMethod(model, device)\n",
        "}\n",
        "\n",
        "results_all_methods = {}\n",
        "\n",
        "for method_name, xai_method in methods.items():\n",
        "    print(f\"\\nProcessing method: {method_name}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    fass_calc = FASSCalculator(xai_method)\n",
        "    all_fass_scores = []\n",
        "    all_detailed_results = []\n",
        "\n",
        "    for batch_start in range(0, NUM_IMAGES, BATCH_SIZE):\n",
        "        batch_end = min(batch_start + BATCH_SIZE, NUM_IMAGES)\n",
        "        print(f\"\\nBatch {batch_start//BATCH_SIZE + 1}: Images {batch_start}-{batch_end}\")\n",
        "\n",
        "        for img_idx in tqdm(range(batch_start, batch_end)):\n",
        "            try:\n",
        "                image_tensor, label = cifar_test[img_idx]\n",
        "                image_pil = transforms.ToPILImage()(image_tensor)\n",
        "\n",
        "                input_tensor = xai_method.preprocess(image_pil)\n",
        "                with torch.no_grad():\n",
        "                    output = model(input_tensor)\n",
        "                    pred_class = output.argmax(dim=1).item()\n",
        "\n",
        "                perturb_gen = PerturbationGenerator(image_pil)\n",
        "                perturbations = perturb_gen.generate_all_perturbations()\n",
        "\n",
        "                result = fass_calc.compute_fass_for_image(image_pil, perturbations, pred_class)\n",
        "                all_fass_scores.append(result['fass_score'])\n",
        "                all_detailed_results.append({\n",
        "                    'image_idx': img_idx,\n",
        "                    'fass_score': result['fass_score'],\n",
        "                    'true_label': label,\n",
        "                    'pred_class': pred_class\n",
        "                })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"\\nError on image {img_idx}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        if (batch_start + BATCH_SIZE) % 100 == 0:\n",
        "            checkpoint = {\n",
        "                'method': method_name,\n",
        "                'scores': all_fass_scores,\n",
        "                'results': all_detailed_results\n",
        "            }\n",
        "            with open(f'results/checkpoint_{method_name}_{batch_start}.pkl', 'wb') as f:\n",
        "                pickle.dump(checkpoint, f)\n",
        "\n",
        "    results_all_methods[method_name] = {\n",
        "        'mean_fass': np.mean(all_fass_scores),\n",
        "        'std_fass': np.std(all_fass_scores),\n",
        "        'median_fass': np.median(all_fass_scores),\n",
        "        'min_fass': np.min(all_fass_scores),\n",
        "        'max_fass': np.max(all_fass_scores),\n",
        "        'all_scores': all_fass_scores,\n",
        "        'detailed_results': all_detailed_results\n",
        "    }\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n{method_name} Summary:\")\n",
        "print(f\"Mean FASS: {results_all_methods[method_name]['mean_fass']:.4f}\")\n",
        "print(f\"Std FASS: {results_all_methods[method_name]['std_fass']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrgvLc5f5YiC",
        "outputId": "9f9e60d7-1c8d-4b3f-f630-e70dd1643053"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "vanilla_gradients Summary:\n",
            "Mean FASS: 0.4208\n",
            "Std FASS: 0.0187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFinal Results:\")\n",
        "print(\"=\"*60)\n",
        "for method_name, stats in results_all_methods.items():\n",
        "    print(f\"{method_name:25s} FASS: {stats['mean_fass']:.4f} ± {stats['std_fass']:.4f}\")\n",
        "\n",
        "with open('results/final_results.pkl', 'wb') as f:\n",
        "    pickle.dump(results_all_methods, f)\n",
        "\n",
        "with open('results/final_results.json', 'w') as f:\n",
        "    results_serializable = {\n",
        "        method: {\n",
        "            'mean_fass': float(stats['mean_fass']),\n",
        "            'std_fass': float(stats['std_fass']),\n",
        "            'median_fass': float(stats['median_fass']),\n",
        "            'min_fass': float(stats['min_fass']),\n",
        "            'max_fass': float(stats['max_fass'])\n",
        "        }\n",
        "        for method, stats in results_all_methods.items()\n",
        "    }\n",
        "    json.dump(results_serializable, f, indent=2)\n",
        "\n",
        "print(\"\\nResults saved to results/final_results.pkl and results/final_results.json\")\n",
        "print(\"Experiment complete\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8al_xBP5Urf",
        "outputId": "1e43d245-b632-40f5-be5e-d9cea6f3e3f4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Results:\n",
            "============================================================\n",
            "integrated_gradients      FASS: 0.4613 ± 0.0241\n",
            "gradcam                   FASS: 0.5576 ± 0.0183\n",
            "vanilla_gradients         FASS: 0.4208 ± 0.0187\n",
            "\n",
            "Results saved to results/final_results.pkl and results/final_results.json\n",
            "Experiment complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L4Ds1LJ_5c2Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}